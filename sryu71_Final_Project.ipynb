{
 "cells": [
  {
   "cellId": "2a0378cc4fb64a2a8c148526473382d8",
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "is_collapsed": false,
    "formattedRanges": [],
    "cell_id": "2a0378cc4fb64a2a8c148526473382d8",
    "deepnote_cell_type": "text-cell-h3"
   },
   "source": "### Import statements",
   "block_group": "53c5f72fe9e74f6ea50e7a805f888206"
  },
  {
   "cellId": "474dbf0e11ab4bfe9ef251e7760983e1",
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "is_collapsed": false,
    "formattedRanges": [
     {
      "type": "marks",
      "marks": {
       "code": true
      },
      "toCodePoint": 63,
      "fromCodePoint": 42
     },
     {
      "url": "https://docs.deepnote.com/environment/python-requirements",
      "type": "link",
      "ranges": [],
      "toCodePoint": 157,
      "fromCodePoint": 153
     }
    ],
    "cell_id": "474dbf0e11ab4bfe9ef251e7760983e1",
    "deepnote_cell_type": "text-cell-p"
   },
   "source": "Since Great Expectations is listed in the requirements.txt file, Deepnote will install it when the hardware starts. Read more about package installation here.",
   "block_group": "e38df518573a4b519ffc853f853a0bcc"
  },
  {
   "cellId": "bce99ff99c5c4605bacb75d52450affe",
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "source_hash": "53ce9696",
    "execution_start": 1762988194200,
    "execution_millis": 3579,
    "deepnote_cell_height": 225,
    "execution_context_id": "15b6ab09-ca43-4510-bde1-fad838be0c87",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 6
    },
    "cell_id": "bce99ff99c5c4605bacb75d52450affe",
    "deepnote_cell_type": "code"
   },
   "source": "# CS 6603 Final Group project: Mark P Abbott - mabbott7, Michael Countouris - mcountouris3, Soon Ryu - sryu71\n\n# Import libraries we need for this project\nimport pandas as pd  # for working with data tables\nimport numpy as np  # for math calculations\nimport matplotlib.pyplot as plt  # for making graphs\nimport seaborn as sns  # for making nice graphs\nfrom sklearn.preprocessing import RobustScaler  # for scaling data\nfrom sklearn.model_selection import train_test_split  # for splitting data into train/test\nfrom sklearn import tree  # for decision tree model\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix  # for checking model performance\nfrom aif360.datasets import BinaryLabelDataset  # for fairness analysis\nfrom aif360.algorithms.preprocessing import Reweighing  # for fixing bias in data",
   "block_group": "c3059e5e41d74965a437ff5182dad5ad",
   "execution_count": null,
   "outputs": [],
   "outputs_reference": "s3:deepnote-cell-outputs-production/d5a22796-a002-418e-afe2-f3e6af3f11d6",
   "content_dependencies": null
  },
  {
   "cellId": "5e3783f4c9a646f1b68e212a2e769cf8",
   "cell_type": "code",
   "metadata": {
    "source_hash": "8ad21bd6",
    "execution_start": 1762988197835,
    "execution_millis": 264,
    "execution_context_id": "15b6ab09-ca43-4510-bde1-fad838be0c87",
    "cell_id": "5e3783f4c9a646f1b68e212a2e769cf8",
    "deepnote_cell_type": "code"
   },
   "source": "# STEP 1: Dataset Analysis\n\n# Load the CSV file into a data table\ndf = pd.read_csv('WA_Fn-UseC_-HR-Employee-Attrition.csv', encoding='utf-8-sig', on_bad_lines='skip')\n\nprint(\"=\"*60)\nprint(\"STEP 1: DATASET ANALYSIS RESULTS\")\nprint(\"=\"*60)\n\n# Show which dataset we are using\nprint(\"\\n1. DATASET SELECTED: Employee Attrition\")\nprint(\"   Name: WA_Fn-UseC_-HR-Employee-Attrition.csv\")\nprint(\"   Link: https://www.kaggle.com/datasets/patelprashant/employee-attrition\")\n\n# Show what domain this is\nprint(\"\\n2. REGULATED DOMAIN:\")\nprint(\"   Employment (HR/Human Resources)\")\n\n# Count how many rows in the data\nprint(f\"\\n3. NUMBER OF OBSERVATIONS:\")\nprint(f\"   {len(df)} observations\")\n\n# Count how many columns in the data\nprint(f\"\\n4. NUMBER OF VARIABLES:\")\nprint(f\"   {len(df.columns)} variables\")\n\n# Show the outcome variables we will predict\nprint(f\"\\n5. DEPENDENT/OUTCOME VARIABLES:\")\nprint(\"   - Attrition (Primary): Employee turnover (Yes/No)\")\nprint(f\"     Values: {list(df['Attrition'].unique())}\")\n\n# Count how many Yes and No for Attrition\nattrition_counts = df['Attrition'].value_counts()\ntotal = len(df)\nno_pct = (attrition_counts['No'] / total) * 100\nyes_pct = (attrition_counts['Yes'] / total) * 100\nprint(f\"     Distribution: No: {attrition_counts['No']} ({no_pct:.1f}%), Yes: {attrition_counts['Yes']} ({yes_pct:.1f}%)\")\n\nprint()\nprint(\"   - PerformanceRating (Secondary): Performance score\")\nprint(f\"     Values: {list(df['PerformanceRating'].unique())}\")\n\n# Count performance ratings\nperf_counts = df['PerformanceRating'].value_counts()\nrating3_pct = (perf_counts[3] / total) * 100\nrating4_pct = (perf_counts[4] / total) * 100\nprint(f\"     Distribution: Rating 3: {perf_counts[3]} ({rating3_pct:.1f}%), Rating 4: {perf_counts[4]} ({rating4_pct:.1f}%)\")\n\n# Show protected class variables (Age, Gender, MaritalStatus)\nprint(f\"\\n6. PROTECTED CLASS VARIABLES:\")\nprint(f\"   Total: 3 protected class variables\")\nprint()\nprint(\"   - Age (Continuous)\")\nprint(f\"     Range: {df['Age'].min()} to {df['Age'].max()} years\")\nprint()\nprint(\"   - Gender (Categorical)\")\nprint(f\"     Values: {list(df['Gender'].unique())}\")\n\n# Count male and female\ngender_counts = df['Gender'].value_counts()\nmale_pct = (gender_counts['Male'] / total) * 100\nfemale_pct = (gender_counts['Female'] / total) * 100\nprint(f\"     Distribution: Male: {gender_counts['Male']} ({male_pct:.1f}%), Female: {gender_counts['Female']} ({female_pct:.1f}%)\")\n\nprint()\nprint(\"   - MaritalStatus (Categorical)\")\nprint(f\"     Values: {list(df['MaritalStatus'].unique())}\")\n\n# Count married, single, divorced\nmarital_counts = df['MaritalStatus'].value_counts()\nmarried_pct = (marital_counts['Married'] / total) * 100\nsingle_pct = (marital_counts['Single'] / total) * 100\ndivorced_pct = (marital_counts['Divorced'] / total) * 100\nprint(f\"     Distribution: Married: {marital_counts['Married']} ({married_pct:.1f}%), Single: {marital_counts['Single']} ({single_pct:.1f}%), Divorced: {marital_counts['Divorced']} ({divorced_pct:.1f}%)\")\n\n# Show the laws that protect each class\nprint(f\"\\n7. LEGAL PRECEDENCE FOR EACH PROTECTED CLASS:\")\nprint(\"   - Age: Age Discrimination in Employment Act (ADEA)\")\nprint(\"         Protects workers 40+ years old\")\nprint()\nprint(\"   - Gender: Title VII of Civil Rights Act of 1964\")\nprint(\"           Prohibits employment discrimination based on sex\")\nprint()\nprint(\"   - MaritalStatus: Fair Employment and Housing Act\")\nprint(\"                  Prohibits discrimination based on marital status\")\n\n# Check if data meets project requirements\nprint(f\"\\n8. PROJECT REQUIREMENTS CHECK:\")\nprint(f\"   ✓ At least 500 observations? YES ({len(df)} observations)\")\nprint(f\"   ✓ At least 2 protected classes? YES (3 classes)\")\nprint(f\"   ✓ At least 2 dependent variables? YES (2 variables)\")\nprint(f\"   ✓ Related to regulated domain? YES (Employment)\")\n\n# Check for missing data\nprint(f\"\\n9. DATA QUALITY CHECK:\")\nmissing_count = df.isnull().sum().sum()\nif missing_count == 0:\n    print(\"   ✓ No missing values found!\")\nelse:\n    print(f\"   ⚠ {missing_count} missing values found\")",
   "block_group": "97c19c7342584e50a943bb5ef5c61b4b",
   "execution_count": null,
   "outputs": [],
   "outputs_reference": "s3:deepnote-cell-outputs-production/b3062812-a31f-4a05-b447-801273bede79",
   "content_dependencies": null
  },
  {
   "cellId": "dadefed5f93a4c86ba32a6211443a02b",
   "cell_type": "code",
   "metadata": {
    "source_hash": "a8a76bc5",
    "execution_start": 1762988198145,
    "execution_millis": 0,
    "execution_context_id": "15b6ab09-ca43-4510-bde1-fad838be0c87",
    "cell_id": "dadefed5f93a4c86ba32a6211443a02b",
    "deepnote_cell_type": "code"
   },
   "source": "# Check if AIF360 library is installed\n# AIF360 is used for fairness analysis\ntry:\n    import aif360\n    print(\"✅ AIF360 successfully installed!\")\n    print(\"Version:\", aif360.__version__)\nexcept ImportError as e:\n    print(\"❌ AIF360 installation failed:\", e)",
   "block_group": "9d33ce67b7e7449592b3d13fffaca794",
   "execution_count": null,
   "outputs": [],
   "outputs_reference": "dbtable:cell_outputs/322ff722-5321-4d59-a1c9-86808a5cff54",
   "content_dependencies": null
  },
  {
   "cellId": "2d78642fd5374581b351ee414ee06585",
   "cell_type": "code",
   "metadata": {
    "source_hash": "a4d1041",
    "execution_start": 1762988198195,
    "execution_millis": 0,
    "execution_context_id": "15b6ab09-ca43-4510-bde1-fad838be0c87",
    "cell_id": "2d78642fd5374581b351ee414ee06585",
    "deepnote_cell_type": "code"
   },
   "source": "# Step 2: Dataset exploration\n\n# 2.1 Show all the protected class groups\nprint(\"=== STEP 2.1: Protected Class Subgroups ===\")\nprint(\"Age groups:\", df['Age'].unique()[:10], \"... (continuous)\")\nprint(\"Gender:\", df['Gender'].unique())\nprint(\"MaritalStatus:\", df['MaritalStatus'].unique())\n\n# 2.2 Convert text to numbers\nprint(\"\\n=== STEP 2.2: Discretize Subgroups ===\")\n# Change Male/Female to 0/1\ndf['Gender_num'] = df['Gender'].map({'Male': 0, 'Female': 1})\n# Change marital status to numbers\ndf['MaritalStatus_num'] = df['MaritalStatus'].map({'Single': 0, 'Married': 1, 'Divorced': 2})\n# Change Attrition to numbers\ndf['Attrition_num'] = df['Attrition'].map({'No': 0, 'Yes': 1})\n# Change performance rating to numbers\ndf['PerformanceRating_num'] = df['PerformanceRating'].map({3: 0, 4: 1})\n\nprint(\"Gender mapping: Male=0, Female=1\")\nprint(\"MaritalStatus mapping: Single=0, Married=1, Divorced=2\") \nprint(\"Attrition mapping: No=0, Yes=1\")\nprint(\"PerformanceRating mapping: 3=0, 4=1\")\n\n# 2.3 Choose two protected classes for analysis\nprint(\"\\n=== STEP 2.3: Selected Protected Classes ===\")\nprint(\"1. Gender\")\nprint(\"2. MaritalStatus\")\n\n# 2.4 Make tables to count combinations\nprint(\"\\n=== STEP 2.4: Frequency Tables ===\")\nprint(\"Gender vs Attrition:\")\nprint(pd.crosstab(df['Gender'], df['Attrition']))\n\nprint(\"\\nMaritalStatus vs Attrition:\")\nprint(pd.crosstab(df['MaritalStatus'], df['Attrition']))\n\nprint(\"\\nGender vs PerformanceRating:\")\nprint(pd.crosstab(df['Gender'], df['PerformanceRating']))\n\nprint(\"\\nMaritalStatus vs PerformanceRating:\")\nprint(pd.crosstab(df['MaritalStatus'], df['PerformanceRating']))",
   "block_group": "2c0101896f3c41caa5a1d05fcd840a99",
   "execution_count": null,
   "outputs": [],
   "outputs_reference": "s3:deepnote-cell-outputs-production/ba825c2c-f240-49cc-817c-c84f2090f7e8",
   "content_dependencies": null
  },
  {
   "cellId": "80e00a081b5f4c6784a8eb6614b858f6",
   "cell_type": "code",
   "metadata": {
    "source_hash": "c682da43",
    "execution_start": 1762988198255,
    "execution_millis": 1294,
    "execution_context_id": "15b6ab09-ca43-4510-bde1-fad838be0c87",
    "cell_id": "80e00a081b5f4c6784a8eb6614b858f6",
    "deepnote_cell_type": "code"
   },
   "source": "# Step 2.5: Create bar charts to visualize the data\nplt.figure(figsize=(15, 10))\n\n# Chart 1: Count of Gender vs Attrition\nplt.subplot(2, 2, 1)\ngender_attrition = pd.crosstab(df['Gender'], df['Attrition'])\ngender_attrition.plot(kind='bar', ax=plt.gca())\nplt.title('Gender vs Attrition')\nplt.xlabel('Gender')\nplt.ylabel('Count')\nplt.xticks(rotation=45)\n\n# Chart 2: Count of MaritalStatus vs Attrition  \nplt.subplot(2, 2, 2)\nmarital_attrition = pd.crosstab(df['MaritalStatus'], df['Attrition'])\nmarital_attrition.plot(kind='bar', ax=plt.gca())\nplt.title('Marital Status vs Attrition')\nplt.xlabel('Marital Status')\nplt.ylabel('Count')\nplt.xticks(rotation=45)\n\n# Chart 3: Count of Gender vs PerformanceRating\nplt.subplot(2, 2, 3)\ngender_performance = pd.crosstab(df['Gender'], df['PerformanceRating'])\ngender_performance.plot(kind='bar', ax=plt.gca())\nplt.title('Gender vs Performance Rating')\nplt.xlabel('Gender')\nplt.ylabel('Count')\nplt.xticks(rotation=45)\n\n# Chart 4: Count of MaritalStatus vs PerformanceRating\nplt.subplot(2, 2, 4)\nmarital_performance = pd.crosstab(df['MaritalStatus'], df['PerformanceRating'])\nmarital_performance.plot(kind='bar', ax=plt.gca())\nplt.title('Marital Status vs Performance Rating')\nplt.xlabel('Marital Status')\nplt.ylabel('Count')\nplt.xticks(rotation=45)\n\n# Save and show the charts\nplt.tight_layout()\nplt.savefig('2_5_protected_class_charts.png')\nplt.show()\nplt.close()",
   "block_group": "db4189e1006541929f98e5a996b0c883",
   "execution_count": null,
   "outputs": [],
   "outputs_reference": "s3:deepnote-cell-outputs-production/30a44222-22dc-47ce-891b-63a7005f6352",
   "content_dependencies": null
  },
  {
   "cellId": "babc78282a8f44759f2bae5a22c9a97d",
   "cell_type": "code",
   "metadata": {
    "source_hash": "ecbbedfc",
    "execution_start": 1762988201144,
    "execution_millis": 1,
    "execution_context_id": "15b6ab09-ca43-4510-bde1-fad838be0c87",
    "cell_id": "babc78282a8f44759f2bae5a22c9a97d",
    "deepnote_cell_type": "code"
   },
   "source": "# Data Preprocessing: Prepare data for machine learning model\n\n# Convert OverTime to numbers (1 = No, 0 = Yes)\ndf['OverTime'] = (df['OverTime'] == 'No').astype(int)\n\n# These columns don't help - remove them\ndrop_cols = ['EmployeeCount', 'EmployeeNumber', 'Over18', 'StandardHours']\n\n# These columns have categories like job role, department\ncategorical_features = ['BusinessTravel', 'Department', 'EducationField', 'JobRole']\n\n# These columns have numbers like salary, age\nnumerical_features = ['DailyRate', 'DistanceFromHome', 'Education', 'EnvironmentSatisfaction', 'HourlyRate', 'JobInvolvement', 'JobLevel',\n 'JobSatisfaction', 'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked', 'PercentSalaryHike', 'RelationshipSatisfaction', 'StockOptionLevel',\n 'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance', 'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager']\n\n# These columns we will convert to binary later\nvariable_features = ['Age', 'Gender', 'MaritalStatus', 'PerformanceRating', 'Attrition'] \n\n# Remove useless columns\ndf = df.drop(columns=drop_cols)\n\n# Get categorical columns\ndf_cat = df[categorical_features]\n\n# Convert categories to binary columns (OneHotEncoding)\ndf_ohe = pd.get_dummies(df_cat, dtype=int)\n# Add back numerical columns\ndf_ohe[numerical_features] = df[numerical_features]\n# Add back variable columns\ndf_ohe[variable_features] = df[variable_features]\n# Replace old dataframe with new one\ndf = df_ohe.copy()",
   "block_group": "d39981bd05724832bf2ca19f2a3fdd71",
   "execution_count": null,
   "outputs": [],
   "outputs_reference": null,
   "content_dependencies": null
  },
  {
   "cellId": "eea9a1b1fa8a4667b1ba143d1d40b694",
   "cell_type": "code",
   "metadata": {
    "source_hash": "e2124847",
    "execution_start": 1762988201195,
    "execution_millis": 0,
    "execution_context_id": "15b6ab09-ca43-4510-bde1-fad838be0c87",
    "cell_id": "eea9a1b1fa8a4667b1ba143d1d40b694",
    "deepnote_cell_type": "code"
   },
   "source": "print(\"3.1: PRIVILEGED AND UNPRIVILEGED GROUPS:\\n\")\n\n# Define which groups are privileged and unprivileged for each protected class\nprotected_classes_info = {\n    'Age': {\n        'privileged': 'Less than 40 years old',  # younger workers\n        'unprivileged': '40+ years old'  # older workers\n    },\n    'Gender': {\n        'privileged': 'Male',  # men\n        'unprivileged': 'Female'  # women\n    },\n    'MaritalStatus': {\n        'privileged': 'Married',  # married people\n        'unprivileged': 'Single or Divorced'  # not married\n    }\n}\n\n# Print the information\nfor pc, groups in protected_classes_info.items():\n    print(f\"Protected Class: {pc}\")\n    print(f\"- Privileged Group: {groups['privileged']}\")\n    print(f\"- Unprivileged Group: {groups['unprivileged']}\")",
   "block_group": "5b866b5f46aa460c8ebe3db2cb21d89f",
   "execution_count": null,
   "outputs": [],
   "outputs_reference": "dbtable:cell_outputs/2c5001b0-5444-4c0e-ad4c-1a5f4ad37b25",
   "content_dependencies": null
  },
  {
   "cellId": "d1fca020e2bf451c9c628f419fe5c772",
   "cell_type": "code",
   "metadata": {
    "source_hash": "f5931bb2",
    "execution_start": 1762988201244,
    "execution_millis": 1,
    "execution_context_id": "15b6ab09-ca43-4510-bde1-fad838be0c87",
    "cell_id": "d1fca020e2bf451c9c628f419fe5c772",
    "deepnote_cell_type": "code"
   },
   "source": "print(\"Creating binary variable mappings\")\n\n# Convert protected classes to binary (0 or 1)\n# 1 = privileged group, 0 = unprivileged group\n\ndf['Age_Bin'] = (df['Age'] < 40).astype(int)  # 1 = younger than 40, 0 = 40 or older\ndf['Gender_Bin'] = (df['Gender'] == 'Male').astype(int)  # 1 = Male, 0 = Female\ndf['MaritalStatus_Bin'] = (df['MaritalStatus'] == 'Married').astype(int)  # 1 = Married, 0 = Single or Divorced\n\n# Convert outcomes to binary\ndf['Attrition_Bin'] = (df['Attrition'] == 'No').astype(int)  # 1 = stayed, 0 = left\ndf['PerformanceRating_Bin'] = (df['PerformanceRating'] == 4).astype(int)  # 1 = high rating, 0 = low rating",
   "block_group": "8303517e0e9a406fa40489f74e923f66",
   "execution_count": null,
   "outputs": [],
   "outputs_reference": "dbtable:cell_outputs/a0ba23cc-f296-4173-90c4-d44197754c94",
   "content_dependencies": null
  },
  {
   "cellId": "e2f99e63a085474499a1284da7456143",
   "cell_type": "code",
   "metadata": {
    "source_hash": "d792e11d",
    "execution_start": 1762988201295,
    "execution_millis": 0,
    "execution_context_id": "15b6ab09-ca43-4510-bde1-fad838be0c87",
    "cell_id": "e2f99e63a085474499a1284da7456143",
    "deepnote_cell_type": "code"
   },
   "source": "print(\"Fairness Metric Functions\")\n\n# Function 1: Disparate Impact\n# Measures fairness by comparing rates between groups\n# Goal: value should be close to 1.0 (fair is 0.8 to 1.25)\ndef compute_disparate_impact(df, protected_attr, outcome_attr):\n    # Split into privileged (1) and unprivileged (0) groups\n    priv = df[df[protected_attr] == 1]\n    unpriv = df[df[protected_attr] == 0]\n\n    # Check if groups exist\n    if len(priv) == 0 or len(unpriv) == 0:\n        return np.nan\n\n    # Calculate positive outcome rate for each group\n    priv_rate = priv[outcome_attr].sum() / len(priv)\n    unpriv_rate = unpriv[outcome_attr].sum() / len(unpriv)\n\n    # Can't divide by zero\n    if priv_rate == 0:\n        return np.nan\n    # Return ratio of rates\n    return unpriv_rate / priv_rate\n\n# Function 2: Statistical Parity Difference\n# Measures fairness by comparing differences between groups\n# Goal: value should be close to 0.0 (fair is -0.1 to 0.1)\ndef compute_statistical_parity_difference(df, protected_attr, outcome_attr):\n    # Split into privileged (1) and unprivileged (0) groups\n    priv = df[df[protected_attr] == 1]\n    unpriv = df[df[protected_attr] == 0]\n\n    # Check if groups exist\n    if len(priv) == 0 or len(unpriv) == 0:\n        return np.nan\n\n    # Calculate positive outcome rate for each group\n    priv_rate = priv[outcome_attr].sum() / len(priv)\n    unpriv_rate = unpriv[outcome_attr].sum() / len(unpriv)\n    # Return difference of rates\n    return unpriv_rate - priv_rate",
   "block_group": "433610291f824df9ae6c7e4925424215",
   "execution_count": null,
   "outputs": [],
   "outputs_reference": "dbtable:cell_outputs/b3a1a6d4-1f59-4e22-894a-dc62e20586ca",
   "content_dependencies": null
  },
  {
   "cellId": "5830609dba3044b2b158a34385db3ef8",
   "cell_type": "code",
   "metadata": {
    "source_hash": "53d52cb2",
    "execution_start": 1762988201355,
    "execution_millis": 0,
    "execution_context_id": "15b6ab09-ca43-4510-bde1-fad838be0c87",
    "cell_id": "5830609dba3044b2b158a34385db3ef8",
    "deepnote_cell_type": "code"
   },
   "source": "print(\"3.2: COMPUTE FAIRNESS METRICS - ORIGINAL DATASET\")\n\n# Calculate fairness for Gender -> Attrition\ndi_gender_attr = compute_disparate_impact(df, 'Gender_Bin', 'Attrition_Bin')\nspd_gender_attr = compute_statistical_parity_difference(df, 'Gender_Bin', 'Attrition_Bin')\n\n# Calculate fairness for Gender -> PerformanceRating\ndi_gender_perf = compute_disparate_impact(df, 'Gender_Bin', 'PerformanceRating_Bin')\nspd_gender_perf = compute_statistical_parity_difference(df, 'Gender_Bin', 'PerformanceRating_Bin')\n\n# Calculate fairness for MaritalStatus -> Attrition\ndi_maritalStatus_attr = compute_disparate_impact(df, 'MaritalStatus_Bin', 'Attrition_Bin')\nspd_maritalStatus_attr = compute_statistical_parity_difference(df, 'MaritalStatus_Bin', 'Attrition_Bin')\n\n# Calculate fairness for MaritalStatus -> PerformanceRating\ndi_maritalStatus_perf = compute_disparate_impact(df, 'MaritalStatus_Bin', 'PerformanceRating_Bin')\nspd_maritalStatus_perf = compute_statistical_parity_difference(df, 'MaritalStatus_Bin', 'PerformanceRating_Bin')\n\n# Put all results in a table\nresults_original = pd.DataFrame({\n    'Protected Class': ['Gender', 'Gender', 'MaritalStatus', 'MaritalStatus'],\n    'Outcome Variable': ['Attrition', 'PerformanceRating', 'Attrition', 'PerformanceRating'],\n    'Disparate Impact': [di_gender_attr, di_gender_perf, di_maritalStatus_attr, di_maritalStatus_perf],\n    'Statistical Parity Difference': [spd_gender_attr, spd_gender_perf, spd_maritalStatus_attr, spd_maritalStatus_perf]\n})\n\n# Show the table\nprint()\nprint(\"SUMMARY TABLE - ORIGINAL DATASET:\")\nprint(results_original.to_string(index=False))",
   "block_group": "10caa2545fed40c9ad0388244f6c26dd",
   "execution_count": null,
   "outputs": [],
   "outputs_reference": "dbtable:cell_outputs/9d641b21-542d-4f51-ba11-74a946723365",
   "content_dependencies": null
  },
  {
   "cellId": "af86663def794ed68d8307f2b904f8b8",
   "cell_type": "code",
   "metadata": {
    "source_hash": "83a9da10",
    "execution_start": 1762988201415,
    "execution_millis": 0,
    "execution_context_id": "15b6ab09-ca43-4510-bde1-fad838be0c87",
    "cell_id": "af86663def794ed68d8307f2b904f8b8",
    "deepnote_cell_type": "code"
   },
   "source": "print(\"3.3: APPLY REWEIGHING (AIF360)\")\n\n# Get only number columns\ndf_numeric = df.select_dtypes(include=[np.number]).copy()\n\n# Create AIF360 dataset format\ndataset_orig = BinaryLabelDataset(\n    favorable_label=1,  # 1 = good outcome\n    unfavorable_label=0,  # 0 = bad outcome\n    df=df_numeric,\n    label_names=['Attrition_Bin'],  # what we want to predict\n    protected_attribute_names=['Gender_Bin', 'MaritalStatus_Bin']  # protected classes\n)\n\n# Define privileged group (Male and Married)\npriv_groups = [{'Gender_Bin': 1, 'MaritalStatus_Bin': 1}]\n# Define unprivileged groups (all other combinations)\nunpriv_groups = [\n    {'Gender_Bin': 0, 'MaritalStatus_Bin': 0},  # Female and Single/Divorced\n    {'Gender_Bin': 0, 'MaritalStatus_Bin': 1},  # Female and Married\n    {'Gender_Bin': 1, 'MaritalStatus_Bin': 0}   # Male and Single/Divorced\n]\n\n# Create reweighing object\nRW = Reweighing(privileged_groups=priv_groups,unprivileged_groups=unpriv_groups)\n\n# Apply reweighing to fix bias\ndataset_transf = RW.fit_transform(dataset_orig)\n\n# Add weights back to dataframe\ndf.loc[df_numeric.index, 'weight'] = dataset_transf.instance_weights\n\n# Show weight range\nprint(f\"Weight range: [{df['weight'].min()}, {df['weight'].max()}]\")",
   "block_group": "7817ed0098444f26bd60ef84c2e210b6",
   "execution_count": null,
   "outputs": [],
   "outputs_reference": "dbtable:cell_outputs/91a98e17-319e-478b-b0ff-fc3780082d3e",
   "content_dependencies": null
  },
  {
   "cellId": "91489b164c5f41a9ba0c95c87ceda98e",
   "cell_type": "code",
   "metadata": {
    "source_hash": "a5d27138",
    "execution_start": 1762988201465,
    "execution_millis": 0,
    "execution_context_id": "15b6ab09-ca43-4510-bde1-fad838be0c87",
    "cell_id": "91489b164c5f41a9ba0c95c87ceda98e",
    "deepnote_cell_type": "code"
   },
   "source": "print(\"Weighted Fairness Metric Functions\")\n\n# Helper function: Calculate weighted rate\n# This accounts for the weights we added with reweighing\ndef _weighted_rate(group_df, outcome_attr):\n    w = group_df['weight']  # get weights\n    if w.sum() == 0:  # avoid divide by zero\n        return np.nan\n    # Calculate weighted average\n    return (group_df[outcome_attr] * w).sum() / w.sum()\n\n# Disparate Impact with weights\ndef compute_disparate_impact_weighted(df, protected_attr, outcome_attr):\n    # Split into privileged and unprivileged groups\n    priv = df[df[protected_attr] == 1]\n    unpriv = df[df[protected_attr] == 0]\n    # Get weighted rates for each group\n    priv_rate = _weighted_rate(priv, outcome_attr)\n    unpriv_rate = _weighted_rate(unpriv, outcome_attr)\n    # Can't divide by zero\n    if priv_rate == 0:\n        return np.nan\n    # Return ratio\n    return unpriv_rate / priv_rate\n\n# Statistical Parity Difference with weights\ndef compute_statistical_parity_difference_weighted(df, protected_attr, outcome_attr):\n    # Split into privileged and unprivileged groups\n    priv = df[df[protected_attr] == 1]\n    unpriv = df[df[protected_attr] == 0]\n    # Get weighted rates for each group\n    priv_rate = _weighted_rate(priv, outcome_attr)\n    unpriv_rate = _weighted_rate(unpriv, outcome_attr)\n    # Return difference\n    return unpriv_rate - priv_rate",
   "block_group": "261842c6ef03422c841028dc08f48c82",
   "execution_count": null,
   "outputs": [],
   "outputs_reference": "dbtable:cell_outputs/f3891832-1d74-4a61-ba4e-ad0206898f8f",
   "content_dependencies": null
  },
  {
   "cellId": "6700dde2a33240e29ebe3e60906d0d1c",
   "cell_type": "code",
   "metadata": {
    "source_hash": "82563b7d",
    "execution_start": 1762988201535,
    "execution_millis": 0,
    "execution_context_id": "15b6ab09-ca43-4510-bde1-fad838be0c87",
    "cell_id": "6700dde2a33240e29ebe3e60906d0d1c",
    "deepnote_cell_type": "code"
   },
   "source": "print(\"3.4: COMPUTE FAIRNESS METRICS - TRANSFORMED DATASET\")\n\n# Calculate weighted fairness for Gender -> Attrition\ndi_gender_attr_w = compute_disparate_impact_weighted(df, 'Gender_Bin', 'Attrition_Bin')\nspd_gender_attr_w = compute_statistical_parity_difference_weighted(df, 'Gender_Bin', 'Attrition_Bin')\n\n# Calculate weighted fairness for Gender -> PerformanceRating\ndi_gender_perf_w = compute_disparate_impact_weighted(df, 'Gender_Bin', 'PerformanceRating_Bin')\nspd_gender_perf_w = compute_statistical_parity_difference_weighted(df, 'Gender_Bin', 'PerformanceRating_Bin')\n\n# Calculate weighted fairness for MaritalStatus -> Attrition\ndi_maritalStatus_attr_w = compute_disparate_impact_weighted(df, 'MaritalStatus_Bin', 'Attrition_Bin')\nspd_maritalStatus_attr_w = compute_statistical_parity_difference_weighted(df, 'MaritalStatus_Bin', 'Attrition_Bin')\n\n# Calculate weighted fairness for MaritalStatus -> PerformanceRating\ndi_maritalStatus_perf_w = compute_disparate_impact_weighted(df, 'MaritalStatus_Bin', 'PerformanceRating_Bin')\nspd_maritalStatus_perf_w = compute_statistical_parity_difference_weighted(df, 'MaritalStatus_Bin', 'PerformanceRating_Bin')\n\n# Put all results in a table\nresults_transformed = pd.DataFrame({\n    'Protected Class': ['Gender', 'Gender', 'MaritalStatus', 'MaritalStatus'],\n    'Outcome Variable': ['Attrition', 'PerformanceRating', 'Attrition', 'PerformanceRating'],\n    'Disparate Impact': [di_gender_attr_w, di_gender_perf_w, di_maritalStatus_attr_w, di_maritalStatus_perf_w],\n    'Statistical Parity Difference': [spd_gender_attr_w, spd_gender_perf_w, spd_maritalStatus_attr_w, spd_maritalStatus_perf_w]\n})\n\n# Show the table\nprint()\nprint(\"SUMMARY TABLE - TRANSFORMED DATASET:\")\nprint(results_transformed.to_string(index=False))",
   "block_group": "e02d723a5e414ad9bac67f88b8a829d9",
   "execution_count": null,
   "outputs": [],
   "outputs_reference": "dbtable:cell_outputs/d4151906-8918-46eb-ad35-86da41c40d39",
   "content_dependencies": null
  },
  {
   "cellId": "9fc793fc914f41b5a04ab79c79670b84",
   "cell_type": "code",
   "metadata": {
    "source_hash": "824b14fc",
    "execution_start": 1762988201595,
    "execution_millis": 0,
    "execution_context_id": "15b6ab09-ca43-4510-bde1-fad838be0c87",
    "cell_id": "9fc793fc914f41b5a04ab79c79670b84",
    "deepnote_cell_type": "code"
   },
   "source": "# Step 4 Setup: Create two datasets for comparison\n\n# Original dataset: no changes (weight = 1.0 for all rows)\ndf_original = df.copy()\ndf_original['weight'] = 1.0\n\n# Transformed dataset: has weights from reweighing\ndf_transformed = df.copy()\n\n# Get the target labels (what we want to predict)\ny_original = df_original['Attrition_Bin']  # 1 = stayed, 0 = left\ny_transformed = df_transformed['Attrition_Bin']\n\n# Get the weights for transformed dataset\nsample_weights = df_transformed['weight']\n\nprint(\"Step 4 handoff:\")\nprint(\"- df_original\")\nprint(\"- df_transformed\")\nprint(\"- y_original\")\nprint(\"- y_transformed\")\nprint(\"- sample_weights\")",
   "block_group": "5d23629a020f4e65a46ce5abd22cb272",
   "execution_count": null,
   "outputs": [],
   "outputs_reference": "dbtable:cell_outputs/7e2ffcf2-8dcc-47b7-b110-f38e665d249f",
   "content_dependencies": null
  },
  {
   "cellId": "2673ed92eb6e444dbd169a1c80d938e1",
   "cell_type": "code",
   "metadata": {
    "source_hash": "6e8f124f",
    "execution_start": 1762988201655,
    "execution_millis": 3,
    "execution_context_id": "15b6ab09-ca43-4510-bde1-fad838be0c87",
    "cell_id": "2673ed92eb6e444dbd169a1c80d938e1",
    "deepnote_cell_type": "code"
   },
   "source": "print(\"Steps 4.1, 4.2, 4.4, 4.5- Splitting data and training models\")\n\n# Remove columns we don't need anymore\nadditions = ['Attrition_Bin', 'weight']\nstep_3_drop = variable_features + additions\ndf_original = df_original.drop(columns=step_3_drop)\ndf_transformed = df_transformed.drop(columns=step_3_drop)\n\n# Scale numerical features to similar range\n# RobustScaler works well with outliers\nscaler = RobustScaler()\ndf_original[numerical_features] = scaler.fit_transform(df_original[numerical_features])\ndf_transformed[numerical_features] = scaler.fit_transform(df_transformed[numerical_features])\n\n# Split original data into train (80%) and test (20%)\nx_train_org, x_test_org, y_train_org, y_test_org = train_test_split(\n    df_original, y_original, test_size=.2, random_state=42)\n\n# Split transformed data into train and test\nx_train_trans, x_test_trans, y_train_trans, y_test_trans, weights_train, weights_test = train_test_split(\n    df_transformed, y_transformed, sample_weights, test_size=.2, random_state=42)\n\n# Train Decision Tree model on original data\n# Decision Tree learns rules to predict if employee will leave\noriginal_tree = tree.DecisionTreeClassifier(max_depth=5, random_state=42)\noriginal_tree.fit(x_train_org, y_train_org)  # learn from training data\norg_pred = original_tree.predict(x_train_org)  # make predictions on training data\norg_test_pred = original_tree.predict(x_test_org)  # make predictions on test data\ndf_pred = x_train_org.copy()  # create new dataframe\ndf_pred['prediction'] = org_pred  # add predictions\nprint(\"Original Tree Metrics:\")\nprint(\"Training Accuracy:\", accuracy_score(y_train_org,org_pred))\nprint(\"Test Set Accuracy: \", accuracy_score(y_test_org, org_test_pred))\n\n# Train Decision Tree model on transformed data (with weights)\ntransformed_tree = tree.DecisionTreeClassifier(max_depth=5, random_state=42)\ntransformed_tree.fit(x_train_trans, y_train_trans, sample_weight=weights_train)  # use weights to reduce bias\ntrans_pred = transformed_tree.predict(x_train_trans)  # make predictions on training data\ntrans_test_pred = transformed_tree.predict(x_test_org)  # make predictions on test data\ndf_pred_transformed = x_train_trans.copy()  # create new dataframe\ndf_pred_transformed['weight'] = weights_train.copy()  # keep weights for fairness calculations\ndf_pred_transformed['prediction'] = trans_pred  # add predictions\nprint()\nprint(\"Transformed Tree Metrics:\")\nprint(\"Training Accuracy:\", accuracy_score(y_train_trans,trans_pred))\nprint(\"Test Set Accuracy: \", accuracy_score(y_test_trans, trans_test_pred))",
   "block_group": "27cfad03c8ad4266ad33cc84c21343b3",
   "execution_count": null,
   "outputs": [],
   "outputs_reference": "dbtable:cell_outputs/2b83095f-ac8e-4d2d-a9f8-3fed0c1f5205",
   "content_dependencies": null
  },
  {
   "cellId": "28bb8b6618db48359a40e60d0be7ed19",
   "cell_type": "code",
   "metadata": {
    "source_hash": "f8157432",
    "execution_start": 1762988201715,
    "execution_millis": 0,
    "execution_context_id": "15b6ab09-ca43-4510-bde1-fad838be0c87",
    "cell_id": "28bb8b6618db48359a40e60d0be7ed19",
    "deepnote_cell_type": "code"
   },
   "source": "print(\"Steps 4.3 and 4.6- Calculating fairness on model predictions\")\n\n# Calculate fairness metrics for ORIGINAL model predictions\n# Gender fairness\ndi_gender_pred = compute_disparate_impact(df_pred, 'Gender_Bin', 'prediction')\nspd_gender_pred = compute_statistical_parity_difference(df_pred, 'Gender_Bin', 'prediction')\n\n# MaritalStatus fairness\ndi_maritalStatus_pred = compute_disparate_impact(df_pred, 'MaritalStatus_Bin', 'prediction')\nspd_maritalStatus_pred = compute_statistical_parity_difference(df_pred, 'MaritalStatus_Bin', 'prediction')\n\n# Show results in table\nresults_original_pred = pd.DataFrame({\n    'Protected Class': ['Gender', 'MaritalStatus'],\n    'Outcome Variable': ['Attrition', 'Attrition'],\n    'Disparate Impact': [di_gender_pred, di_maritalStatus_pred],\n    'Statistical Parity Difference': [spd_gender_pred, spd_maritalStatus_pred]\n})\n\nprint()\nprint(\"SUMMARY TABLE - ORIGINAL DATASET:\")\nprint(results_original_pred.to_string(index=False))\n\n\n# Calculate fairness metrics for TRANSFORMED model predictions (with weights)\n# Gender fairness\ndi_gender_attr_w_pred = compute_disparate_impact_weighted(df_pred_transformed, 'Gender_Bin', 'prediction')\nspd_gender_attr_w_pred = compute_statistical_parity_difference_weighted(df_pred_transformed, 'Gender_Bin', 'prediction')\n\n# MaritalStatus fairness\ndi_maritalStatus_attr_w = compute_disparate_impact_weighted(df_pred_transformed, 'MaritalStatus_Bin', 'prediction')\nspd_maritalStatus_attr_w = compute_statistical_parity_difference_weighted(df_pred_transformed, 'MaritalStatus_Bin', 'prediction')\n\n# Show results in table\nresults_transformed_pred = pd.DataFrame({\n    'Protected Class': ['Gender', 'MaritalStatus'],\n    'Outcome Variable': ['Attrition', 'Attrition'],\n    'Disparate Impact': [di_gender_attr_w, di_maritalStatus_attr_w],\n    'Statistical Parity Difference': [spd_gender_attr_w, spd_maritalStatus_attr_w]\n})\n\nprint()\nprint(\"SUMMARY TABLE - TRANSFORMED DATASET:\")\nprint(results_transformed_pred.to_string(index=False))",
   "block_group": "d55f2458bd114166acdb5f7965dc9c3b",
   "execution_count": null,
   "outputs": [],
   "outputs_reference": "dbtable:cell_outputs/533632e3-4c1e-4174-89e4-280b0e18475d",
   "content_dependencies": null
  },
  {
   "cellId": "41b9ce69ab0f495ea98de1e09cde5e0b",
   "cell_type": "code",
   "metadata": {
    "source_hash": "fbb74358",
    "execution_start": 1762988201775,
    "execution_millis": 413,
    "execution_context_id": "15b6ab09-ca43-4510-bde1-fad838be0c87",
    "cell_id": "41b9ce69ab0f495ea98de1e09cde5e0b",
    "deepnote_cell_type": "code"
   },
   "source": "print(\"=\"*80)\nprint(\"STEP 5: ANALYSIS\")\nprint(\"=\"*80)\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"5.1: FAIRNESS METRICS COMPARISON\")\nprint(\"=\"*80)\n\n# Collect all fairness metrics from all stages\n# Stage 1: Original Dataset (Step 3.2)\n# Stage 2: Transformed Dataset (Step 3.4)  \n# Stage 3: Classifier Predictions (Steps 4.3 and 4.6)\n\n# Get Gender fairness values from all stages\ngender_di_original_data = di_gender_attr\ngender_di_transformed_data = di_gender_attr_w\ngender_di_original_classifier = di_gender_pred\ngender_di_transformed_classifier = di_gender_attr_w_pred\n\ngender_spd_original_data = spd_gender_attr\ngender_spd_transformed_data = spd_gender_attr_w\ngender_spd_original_classifier = spd_gender_pred\ngender_spd_transformed_classifier = spd_gender_attr_w_pred\n\n# Get MaritalStatus fairness values from all stages\nmarital_di_original_data = di_maritalStatus_attr\nmarital_di_transformed_data = di_maritalStatus_attr_w\nmarital_di_original_classifier = di_maritalStatus_pred\nmarital_di_transformed_classifier = di_maritalStatus_attr_w\n\nmarital_spd_original_data = spd_maritalStatus_attr\nmarital_spd_transformed_data = spd_maritalStatus_attr_w\nmarital_spd_original_classifier = spd_maritalStatus_pred\nmarital_spd_transformed_classifier = spd_maritalStatus_attr_w\n\n# Create comparison table\ncomparison_data = {\n    'Stage': ['Original Data', 'Transformed Data', 'Original Classifier', 'Transformed Classifier'],\n    'Gender - Disparate Impact': [gender_di_original_data, gender_di_transformed_data, \n                  gender_di_original_classifier, gender_di_transformed_classifier],\n    'Gender - Statistical Parity Difference': [gender_spd_original_data, gender_spd_transformed_data, \n                  gender_spd_original_classifier, gender_spd_transformed_classifier],\n    'MaritalStatus - Disparate Impact': [marital_di_original_data, marital_di_transformed_data, \n                        marital_di_original_classifier, marital_di_transformed_classifier],\n    'MaritalStatus - Statistical Parity Difference': [marital_spd_original_data, marital_spd_transformed_data, \n                         marital_spd_original_classifier, marital_spd_transformed_classifier]\n}\n\ncomparison_df = pd.DataFrame(comparison_data)\n\nprint(\"\\nFAIRNESS METRICS COMPARISON TABLE:\")\nprint(comparison_df.to_string(index=False))\n\n# Create graphs to show results\nfig = plt.figure(figsize=(20, 12))\nstages = ['Original\\nData', 'Transformed\\nData', 'Original\\nClassifier', 'Transformed\\nClassifier']\nx_pos = np.arange(len(stages))\nbar_width = 0.35\n\n# Graph 1: Gender Disparate Impact\nax1 = plt.subplot(2, 2, 1)\nbars = ax1.bar(x_pos, comparison_df['Gender - Disparate Impact'], bar_width, \n               color=['#3498db', '#2ecc71', '#e74c3c', '#f39c12'], alpha=0.8)\nax1.axhline(1.0, color='black', linestyle='--', linewidth=2, label='Ideal Fairness (DI=1.0)')\nax1.axhspan(0.8, 1.25, color='green', alpha=0.15, label='Fair Region (0.8-1.25)')\nax1.set_ylabel('Disparate Impact', fontsize=12, fontweight='bold')\nax1.set_title('Gender - Disparate Impact', fontsize=14, fontweight='bold')\nax1.set_xticks(x_pos)\nax1.set_xticklabels(stages, fontsize=10)\nax1.set_ylim(0.7, 1.4)\nax1.legend(loc='upper right')\nax1.grid(axis='y', alpha=0.3)\nfor i, (bar, val) in enumerate(zip(bars, comparison_df['Gender - Disparate Impact'])):\n    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n             f'{val:.3f}', ha='center', va='bottom', fontweight='bold')\n\n# Graph 2: Gender Statistical Parity Difference\nax2 = plt.subplot(2, 2, 2)\nbars = ax2.bar(x_pos, comparison_df['Gender - Statistical Parity Difference'], bar_width, \n              color=['#3498db', '#2ecc71', '#e74c3c', '#f39c12'], alpha=0.8)\nax2.axhline(0.0, color='black', linestyle='--', linewidth=2, label='Ideal Fairness (SPD=0.0)')\nax2.axhspan(-0.1, 0.1, color='green', alpha=0.15, label='Fair Region (-0.1 to 0.1)')\nax2.set_ylabel('Statistical Parity Difference', fontsize=12, fontweight='bold')\nax2.set_title('Gender - Statistical Parity Difference', fontsize=14, fontweight='bold')\nax2.set_xticks(x_pos)\nax2.set_xticklabels(stages, fontsize=10)\nax2.set_ylim(-0.1, 0.1)\nax2.legend(loc='upper right')\nax2.grid(axis='y', alpha=0.3)\nfor i, (bar, val) in enumerate(zip(bars, comparison_df['Gender - Statistical Parity Difference'])):\n    ax2.text(bar.get_x() + bar.get_width()/2, \n             bar.get_height() + (0.005 if val >= 0 else -0.01), \n            f'{val:.3f}', ha='center', va='bottom' if val >= 0 else 'top', fontweight='bold')\n\n# Graph 3: MaritalStatus Disparate Impact\nax3 = plt.subplot(2, 2, 3)\nbars = ax3.bar(x_pos, comparison_df['MaritalStatus - Disparate Impact'], bar_width, \n              color=['#3498db', '#2ecc71', '#e74c3c', '#f39c12'], alpha=0.8)\nax3.axhline(1.0, color='black', linestyle='--', linewidth=2, label='Ideal Fairness (DI=1.0)')\nax3.axhspan(0.8, 1.25, color='green', alpha=0.15, label='Fair Region (0.8-1.25)')\nax3.set_ylabel('Disparate Impact', fontsize=12, fontweight='bold')\nax3.set_title('MaritalStatus - Disparate Impact', fontsize=14, fontweight='bold')\nax3.set_xticks(x_pos)\nax3.set_xticklabels(stages, fontsize=10)\nax3.set_ylim(0.7, 1.4)\nax3.legend(loc='upper right')\nax3.grid(axis='y', alpha=0.3)\nfor i, (bar, val) in enumerate(zip(bars, comparison_df['MaritalStatus - Disparate Impact'])):\n    ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n            f'{val:.3f}', ha='center', va='bottom', fontweight='bold')\n\n# Graph 4: MaritalStatus Statistical Parity Difference\nax4 = plt.subplot(2, 2, 4)\nbars = ax4.bar(x_pos, comparison_df['MaritalStatus - Statistical Parity Difference'], bar_width, \n              color=['#3498db', '#2ecc71', '#e74c3c', '#f39c12'], alpha=0.8)\nax4.axhline(0.0, color='black', linestyle='--', linewidth=2, label='Ideal Fairness (SPD=0.0)')\nax4.axhspan(-0.1, 0.1, color='green', alpha=0.15, label='Fair Region (-0.1 to 0.1)')\nax4.set_ylabel('Statistical Parity Difference', fontsize=12, fontweight='bold')\nax4.set_title('MaritalStatus - Statistical Parity Difference', fontsize=14, fontweight='bold')\nax4.set_xticks(x_pos)\nax4.set_xticklabels(stages, fontsize=10)\nax4.set_ylim(-0.15, 0.05)\nax4.legend(loc='upper right')\nax4.grid(axis='y', alpha=0.3)\nfor i, (bar, val) in enumerate(zip(bars, comparison_df['MaritalStatus - Statistical Parity Difference'])):\n    ax4.text(bar.get_x() + bar.get_width()/2, \n            bar.get_height() + (0.005 if val >= 0 else -0.01), \n            f'{val:.3f}', ha='center', va='bottom' if val >= 0 else 'top', fontweight='bold')\n\nplt.suptitle('Fairness Metrics Analysis Across All Stages\\n(Employee Attrition Prediction)', \n             fontsize=16, fontweight='bold', y=0.995)\nplt.tight_layout(rect=[0, 0, 1, 0.99])\nplt.savefig('Step_5_Fairness_Analysis.png', dpi=300, bbox_inches='tight')\nplt.show()\nplt.close()\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"Graph saved as: Step_5_Fairness_Analysis.png\")\nprint(\"=\"*80)",
   "block_group": "fe8823a15a534871bd7a2fc12da1d37d",
   "execution_count": null,
   "outputs": [],
   "outputs_reference": "s3:deepnote-cell-outputs-production/8830198e-817d-4e96-8c7f-8f53249284d0",
   "content_dependencies": null
  },
  {
   "cell_type": "code",
   "source": "print(\"\\n\" + \"=\"*80)\nprint(\"5.2: CHANGE ANALYSIS\")\nprint(\"=\"*80)\n\n# Function to check if fairness got better, worse, or stayed the same\ndef classify_change(original, transformed, metric_type):\n    # Small changes below this number are ignored\n    threshold = 0.005\n    \n    if metric_type == 'DI':\n        # For Disparate Impact: goal is to get close to 1.0\n        original_distance = abs(original - 1.0)  # how far from 1.0\n        transformed_distance = abs(transformed - 1.0)  # how far from 1.0\n        \n        # Check if change is big enough\n        if abs(transformed_distance - original_distance) < threshold:\n            return 'No Change'\n        elif transformed_distance < original_distance:\n            return 'Positive Change (↑ Fairer)'  # got closer to 1.0\n        else:\n            return 'Negative Change (↓ Less Fair)'  # got farther from 1.0\n    else:  # SPD\n        # For Statistical Parity Difference: goal is to get close to 0.0\n        original_distance = abs(original)  # how far from 0.0\n        transformed_distance = abs(transformed)  # how far from 0.0\n        \n        # Check if change is big enough\n        if abs(transformed_distance - original_distance) < threshold:\n            return 'No Change'\n        elif transformed_distance < original_distance:\n            return 'Positive Change (↑ Fairer)'  # got closer to 0.0\n        else:\n            return 'Negative Change (↓ Less Fair)'  # got farther from 0.0\n\n# TABLE 1: Show how fairness changed after we fixed the data\nprint(\"\\nTABLE 1: CHANGES AFTER DATA TRANSFORMATION (Reweighing)\")\nprint(\"-\" * 80)\n\n# Collect fairness values before and after transformation\ntransform_changes = {\n    'Protected Class': ['Gender', 'Gender', 'MaritalStatus', 'MaritalStatus'],\n    'Fairness Metric': ['Disparate Impact', 'Statistical Parity Diff', 'Disparate Impact', 'Statistical Parity Diff'],\n    'Original Value': [gender_di_original_data, gender_spd_original_data, \n                      marital_di_original_data, marital_spd_original_data],\n    'Transformed Value': [gender_di_transformed_data, gender_spd_transformed_data,\n                         marital_di_transformed_data, marital_spd_transformed_data],\n    'Change Direction': [\n        classify_change(gender_di_original_data, gender_di_transformed_data, 'DI'),\n        classify_change(gender_spd_original_data, gender_spd_transformed_data, 'SPD'),\n        classify_change(marital_di_original_data, marital_di_transformed_data, 'DI'),\n        classify_change(marital_spd_original_data, marital_spd_transformed_data, 'SPD')\n    ]\n}\n\n# Make table and show results\ndf_transform_changes = pd.DataFrame(transform_changes)\ndf_transform_changes['Absolute Change'] = abs(df_transform_changes['Transformed Value'] - \n                                               df_transform_changes['Original Value'])\nprint(df_transform_changes.to_string(index=False))\n\n# TABLE 2: Show how fairness changed after training the model\nprint(\"\\n\" + \"=\"*80)\nprint(\"TABLE 2: CHANGES AFTER CLASSIFIER TRAINING\")\nprint(\"-\" * 80)\nprint(\"\\nA) Original Dataset - Data vs Classifier Predictions\")\nprint(\"-\" * 80)\n\n# Compare original data to original model predictions\nclassifier_original_changes = {\n    'Protected Class': ['Gender', 'Gender', 'MaritalStatus', 'MaritalStatus'],\n    'Fairness Metric': ['Disparate Impact', 'Statistical Parity Diff', 'Disparate Impact', 'Statistical Parity Diff'],\n    'Data Value': [gender_di_original_data, gender_spd_original_data,\n                   marital_di_original_data, marital_spd_original_data],\n    'Classifier Value': [gender_di_original_classifier, gender_spd_original_classifier,\n                        marital_di_original_classifier, marital_spd_original_classifier],\n    'Change Direction': [\n        classify_change(gender_di_original_data, gender_di_original_classifier, 'DI'),\n        classify_change(gender_spd_original_data, gender_spd_original_classifier, 'SPD'),\n        classify_change(marital_di_original_data, marital_di_original_classifier, 'DI'),\n        classify_change(marital_spd_original_data, marital_spd_original_classifier, 'SPD')\n    ]\n}\n\n# Make table\ndf_classifier_orig = pd.DataFrame(classifier_original_changes)\ndf_classifier_orig['Absolute Change'] = abs(df_classifier_orig['Classifier Value'] - \n                                            df_classifier_orig['Data Value'])\nprint(df_classifier_orig.to_string(index=False))\n\nprint(\"\\n\" + \"-\" * 80)\nprint(\"B) Transformed Dataset - Data vs Classifier Predictions\")\nprint(\"-\" * 80)\n\n# Compare transformed data to transformed model predictions\nclassifier_transform_changes = {\n    'Protected Class': ['Gender', 'Gender', 'MaritalStatus', 'MaritalStatus'],\n    'Fairness Metric': ['Disparate Impact', 'Statistical Parity Diff', 'Disparate Impact', 'Statistical Parity Diff'],\n    'Data Value': [gender_di_transformed_data, gender_spd_transformed_data,\n                   marital_di_transformed_data, marital_spd_transformed_data],\n    'Classifier Value': [gender_di_transformed_classifier, gender_spd_transformed_classifier,\n                        marital_di_transformed_classifier, marital_spd_transformed_classifier],\n    'Change Direction': [\n        classify_change(gender_di_transformed_data, gender_di_transformed_classifier, 'DI'),\n        classify_change(gender_spd_transformed_data, gender_spd_transformed_classifier, 'SPD'),\n        classify_change(marital_di_transformed_data, marital_di_transformed_classifier, 'DI'),\n        classify_change(marital_spd_transformed_data, marital_spd_transformed_classifier, 'SPD')\n    ]\n}\n\n# Make table\ndf_classifier_trans = pd.DataFrame(classifier_transform_changes)\ndf_classifier_trans['Absolute Change'] = abs(df_classifier_trans['Classifier Value'] - \n                                             df_classifier_trans['Data Value'])\nprint(df_classifier_trans.to_string(index=False))\n\n# TABLE 3: Compare original model vs transformed model\nprint(\"\\n\" + \"=\"*80)\nprint(\"TABLE 3: OVERALL COMPARISON - Original Model vs Transformed Model\")\nprint(\"-\" * 80)\n\n# Compare the two models\noverall_comparison = {\n    'Protected Class': ['Gender', 'Gender', 'MaritalStatus', 'MaritalStatus'],\n    'Fairness Metric': ['Disparate Impact', 'Statistical Parity Diff', 'Disparate Impact', 'Statistical Parity Diff'],\n    'Original Classifier': [gender_di_original_classifier, gender_spd_original_classifier,\n                           marital_di_original_classifier, marital_spd_original_classifier],\n    'Transformed Classifier': [gender_di_transformed_classifier, gender_spd_transformed_classifier,\n                              marital_di_transformed_classifier, marital_spd_transformed_classifier],\n    'Change Direction': [\n        classify_change(gender_di_original_classifier, gender_di_transformed_classifier, 'DI'),\n        classify_change(gender_spd_original_classifier, gender_spd_transformed_classifier, 'SPD'),\n        classify_change(marital_di_original_classifier, marital_di_transformed_classifier, 'DI'),\n        classify_change(marital_spd_original_classifier, marital_spd_transformed_classifier, 'SPD')\n    ]\n}\n\n# Make table\ndf_overall = pd.DataFrame(overall_comparison)\ndf_overall['Absolute Change'] = abs(df_overall['Transformed Classifier'] - \n                                    df_overall['Original Classifier'])\nprint(df_overall.to_string(index=False))\n\n# Summary of what we found\nprint(\"\\n\" + \"=\"*80)\nprint(\"KEY FINDINGS:\")\nprint(\"=\"*80)\nprint(\"✓ Reweighing improved fairness for MaritalStatus (SPD improved from -0.067 to -0.041)\")\nprint(\"✓ Gender fairness remained stable across all stages (all SPD values within fair region)\")\nprint(\"✓ Transformed classifier showed best fairness for MaritalStatus (SPD = -0.021)\")\nprint(\"⚠ Gender SPD slightly worsened after transformation (0.022 → 0.038)\")\nprint(\"=\"*80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 5.3: Team Member Individual Responses\n\n### Team Member 1: Mark P Abbott (mabbott7)\n\n**Q1: Did any of these approaches seem to work to mitigate bias (or increase fairness)? Explain your reasoning.**\n\n[Your response here - at least one paragraph]\n\n**Q2: Did any group receive a positive advantage?**\n\n[Your response here - at least one paragraph]\n\n**Q3: Were any group disadvantaged by these approaches?**\n\n[Your response here - at least one paragraph]\n\n**Q4: What issues would arise if you used these methods to mitigate bias?**\n\n[Your response here - at least one paragraph]\n\n---\n\n### Team Member 2: Michael Countouris (mcountouris3)\n\n**Q1: Did any of these approaches seem to work to mitigate bias (or increase fairness)? Explain your reasoning.**\n\n[Your response here - at least one paragraph]\n\n**Q2: Did any group receive a positive advantage?**\n\n[Your response here - at least one paragraph]\n\n**Q3: Were any group disadvantaged by these approaches?**\n\n[Your response here - at least one paragraph]\n\n**Q4: What issues would arise if you used these methods to mitigate bias?**\n\n[Your response here - at least one paragraph]\n\n---\n\n### Team Member 3: Soon Ryu (sryu71)\n\n**Q1: Did any of these approaches seem to work to mitigate bias (or increase fairness)? Explain your reasoning.**\n\n[Your response here - at least one paragraph]\n\n**Q2: Did any group receive a positive advantage?**\n\n[Your response here - at least one paragraph]\n\n**Q3: Were any group disadvantaged by these approaches?**\n\n[Your response here - at least one paragraph]\n\n**Q4: What issues would arise if you used these methods to mitigate bias?**\n\n[Your response here - at least one paragraph]",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## 5.2: Analysis - Which Fairness Metric is Best?\n\n### Fairness Metric Evaluation\n\n**Statistical Parity Difference (SPD) is the better fairness metric for this analysis.**\n\n### Justification:\n\n1. **Interpretability**: SPD directly measures the difference in favorable outcome rates between privileged and unprivileged groups. A value of 0 indicates perfect fairness, and values within [-0.1, 0.1] are generally considered acceptable. This makes SPD more intuitive to interpret than Disparate Impact.\n\n2. **Sensitivity to Changes**: SPD shows clearer trends across the different stages of our analysis:\n   - For Gender: SPD increased from 0.022 (original data) to 0.038 (transformed data/classifier), indicating reweighing may have slightly worsened fairness\n   - For MaritalStatus: SPD improved from -0.067 (original data) to -0.041 (transformed data) to -0.021 (transformed classifier), showing positive bias mitigation\n\n3. **Fair Region Alignment**: \n   - For Gender, all SPD values remain within the fair region (-0.1 to 0.1)\n   - For MaritalStatus, SPD values moved closer to 0 (ideal fairness) after transformation and classification\n\n4. **Practical Application**: SPD directly translates to real-world impact - it tells us the percentage point difference in attrition rates between groups, which is meaningful for HR decision-making.\n\n### Key Observations:\n\n- **Disparate Impact** values remained relatively stable across stages, all within the fair region (0.8-1.25)\n- **Statistical Parity Difference** showed more nuanced changes, revealing that reweighing was more effective for MaritalStatus than Gender\n- The transformed classifier showed the best fairness for MaritalStatus (SPD = -0.021), closest to ideal fairness",
   "metadata": {}
  }
 ],
 "metadata": {
  "deepnote_persisted_session": {
   "createdAt": "2025-11-12T23:16:58.104Z"
  },
  "deepnote_app_layout": "article",
  "deepnote_notebook_id": "77c07a5cc45145afaa583db73c052041"
 },
 "nbformat": "4",
 "nbformat_minor": "0",
 "version": "0"
}